{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.initializers import Constant\n",
    "from keras.layers import (Activation, Conv2D, Conv3D, Dense, Dropout, Flatten,\n",
    "                          Input, Lambda, MaxPooling2D)\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from skimage.restoration import (denoise_bilateral, denoise_tv_chambolle,\n",
    "                                 denoise_wavelet, estimate_sigma)\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from vis.regularizers import LPNorm, TotalVariation\n",
    "from vis.utils import utils\n",
    "from vis.visualization import (visualize_activation,\n",
    "                               visualize_activation_with_losses)\n",
    "from tensorflow.contrib import graph_editor as ge\n",
    "from cleverhans.attacks import (FastGradientMethod, MadryEtAl,\n",
    "                                ProjectedGradientDescent, SparseL1Descent)\n",
    "from cleverhans.model import Model as CHModel\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from attribution.InfluenceInvariants import InfluenceInvariants\n",
    "from attribution.ActivationInvariants import ActivationInvariants\n",
    "from attribution.invariant_utils import (probits_from_invariants,\n",
    "                                         smooth_logits_from_invariants,\n",
    "                                         smooth_logit_tensor_from_invariants,\n",
    "                                         smooth_logit_tensor_from_invariant,\n",
    "                                         smooth_probits_from_invariants,\n",
    "                                         smooth_probit_tensor_from_invariants,\n",
    "                                         tally_total_stats)\n",
    "\n",
    "logging.captureWarnings(True)\n",
    "logging.getLogger('tensorflow').setLevel(logging.CRITICAL)\n",
    "logging.getLogger('cleverhans').setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces, fetch_lfw_people\n",
    "\n",
    "# Use only classes that have at least 100 images\n",
    "# There are five such classes in LFW\n",
    "lfw_slice = (slice(68, 196, None), slice(61, 190, None))\n",
    "faces_data = fetch_lfw_people(min_faces_per_person=100, color=True, slice_=lfw_slice)\n",
    "images = faces_data.images\n",
    "n_classes = faces_data.target.max()+1\n",
    "x, y = faces_data.data, keras.utils.to_categorical(faces_data.target, n_classes)\n",
    "images /= 255.0\n",
    "\n",
    "# Use 3/4 for training, the rest for testing\n",
    "N_tr = int(len(x)*0.75)\n",
    "N_te = len(x) - N_tr\n",
    "x_tr, y_tr = x[:N_tr], y[:N_tr]\n",
    "x_te, y_te = x[N_tr:], y[N_tr:]\n",
    "im_tr, im_te = images[:N_tr], images[N_tr:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "features (InputLayer)        (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 128)       3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "logits (Dense)               (None, 5)                 85        \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 101,589\n",
      "Trainable params: 101,589\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "accuracy:\n",
      "train=1.0\n",
      "test=0.81\n"
     ]
    }
   ],
   "source": [
    "inp = keras.layers.Input(shape=im_tr[0].shape, name='features')\n",
    "out = keras.layers.Conv2D(128, (3,3), activation='relu')(inp)\n",
    "out = keras.layers.MaxPooling2D(pool_size=(2,2))(out)\n",
    "out = keras.layers.Conv2D(64, (3,3), activation='relu')(out)\n",
    "out = keras.layers.MaxPooling2D(pool_size=(2,2))(out)\n",
    "out = keras.layers.Conv2D(32, (3,3), activation='relu')(out)\n",
    "out = keras.layers.MaxPooling2D(pool_size=(2,2))(out)\n",
    "out = keras.layers.Conv2D(16, (3,3), activation='relu')(out)\n",
    "out = keras.layers.MaxPooling2D(pool_size=(2,2))(out)\n",
    "out = keras.layers.Flatten()(out)\n",
    "out = keras.layers.Dense(16, activation='relu')(out)\n",
    "out = keras.layers.Dense(y[0].shape[0], name='logits')(out)\n",
    "out = keras.layers.Activation('softmax', name='softmax')(out)\n",
    "model = keras.Model(inp, out)\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()\n",
    "model.load_weights('weights/lfw-small-tf.h5')\n",
    "print('accuracy:')\n",
    "print('train={:.2}'.format(model.evaluate(im_tr, y_tr, verbose=False)[1]))\n",
    "print('test={:.2}'.format(model.evaluate(im_te, y_te, verbose=False)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method below, `get_random_invariants`, does the following:\n",
    "1. Samples $n$ uniform-random points from [0,1] into $x$\n",
    "2. For each class label $l$, runs projected gradient descent (`MadryEtAl` from `cleverhans`) with both $L_\\infty$ and $L_2$ norm over $x$ to create approximately $2n$ points with label $l$, stored in $x_l$\n",
    "3. Concatenates all the labeled random points $x_1, \\ldots, x_l$ into $x'$\n",
    "4. For each layer $t$ specified in `layers`, generate a set of invariants using $x'$\n",
    "\n",
    "Importantly, for influence invariants we exclude activation information (i.e., `multiply_attributions=False` in the invariant constructor). The reason for this will become clear later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasModel(CHModel):\n",
    "    def __init__(self, model, **kwargs):\n",
    "        del kwargs\n",
    "        CHModel.__init__(self, 'model_b', model.output_shape[1], locals())\n",
    "\n",
    "        self.model = model\n",
    "        self.fprop(tf.placeholder(tf.float32, (128,)+model.input_shape[1:]))\n",
    "\n",
    "    def fprop(self, x, **kwargs):\n",
    "        del kwargs\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = K.variable(x)\n",
    "        with tf.variable_scope(self.scope, reuse=tf.AUTO_REUSE):\n",
    "            return dict([(layer.name, keras.Model(self.model.input, layer.output)(x)) for layer in self.model.layers])\n",
    "\n",
    "def get_random_invariants(model, layers, n, x_shape, n_classes, nbiter=50, eps_linf=0.1, eps_l2=5., agg_fn=None, seed=0):\n",
    "    np.random.seed(seed)\n",
    "    rand_data = []\n",
    "    cls_size = n\n",
    "    rand_x = np.random.uniform(size=(cls_size,) + x_shape)\n",
    "    nbiter = 50\n",
    "    for l in range(n_classes):\n",
    "        model_ch = KerasModel(model)\n",
    "        sess = K.get_session()\n",
    "        pgd_params_l2 = {'eps': eps_l2,\n",
    "                         'y_target': to_categorical(np.zeros((1,)) + l, n_classes),\n",
    "                         'eps_iter': eps_l2 / nbiter,\n",
    "                         'nb_iter': nbiter,\n",
    "                         'ord': 2,\n",
    "                         'clip_min': 0.,\n",
    "                         'clip_max': 1.}\n",
    "        pgd_params_linf = {'eps': eps_linf,\n",
    "                           'y_target': to_categorical(np.zeros((1,)) + l, n_classes),\n",
    "                           'eps_iter': eps_linf / nbiter,\n",
    "                           'nb_iter': nbiter,\n",
    "                           'ord': np.inf,\n",
    "                           'clip_min': 0.,\n",
    "                           'clip_max': 1.}\n",
    "        pgd = MadryEtAl(model_ch, sess=sess)\n",
    "        cur_data = []\n",
    "        cur_data.append(pgd.generate_np(rand_x, **pgd_params_l2))\n",
    "        cur_data.append(pgd.generate_np(rand_x, **pgd_params_linf))\n",
    "        rand_data.append(np.concatenate(cur_data, axis=0))\n",
    "        print('generated class', l)\n",
    "\n",
    "    rand_data = np.concatenate(rand_data)\n",
    "\n",
    "    log_model = Model(model.inputs, model.layers[-2].output)\n",
    "    log_model.layers[-1].activation = keras.activations.softplus\n",
    "    log_model = utils.apply_modifications(log_model)\n",
    "\n",
    "    gens = [InfluenceInvariants(log_model, layer=target, agg_fn=agg_fn,\n",
    "                                multiply_activation=False).compile() for target in layers]\n",
    "    invs_by_layer = [gen.get_invariants(rand_data, batch_size = 1) for gen in gens]\n",
    "\n",
    "    return invs_by_layer, gens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence invariants\n",
    "\n",
    "We'll start with `agg_fn=None`, so the invariants refer to specific locations on the feature maps. We'll test all convolutional layers (1-4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [7,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated class 0\n",
      "generated class 1\n",
      "generated class 2\n",
      "generated class 3\n",
      "generated class 4\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-dd6c8c284c90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                             \u001b[0mim_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                             \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                             agg_fn=None)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-97-60487709b89b>\u001b[0m in \u001b[0;36mget_random_invariants\u001b[0;34m(model, layers, n, x_shape, n_classes, nbiter, eps_linf, eps_l2, agg_fn, seed)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     gens = [InfluenceInvariants(log_model, layer=target, agg_fn=agg_fn,\n\u001b[0;32m---> 53\u001b[0;31m                                 multiply_activation=False).compile() for target in layers]\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0minvs_by_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_invariants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgen\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-97-60487709b89b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     gens = [InfluenceInvariants(log_model, layer=target, agg_fn=agg_fn,\n\u001b[0;32m---> 53\u001b[0;31m                                 multiply_activation=False).compile() for target in layers]\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0minvs_by_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_invariants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgen\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/longterm/mfredrik/lib-attribution/attribution/InfluenceInvariants.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, layer, agg_fn, Q, multiply_activation)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         self._attributer = InternalInfluence(\n\u001b[0;32m---> 26\u001b[0;31m             model, self.layer, agg_fn=agg_fn, multiply_activation=multiply_activation)\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/longterm/mfredrik/lib-attribution/attribution/methods.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_in, layer, agg_fn, Q, D, multiply_activation)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0minfluence\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         '''\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInternalInfluence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# Make a clone of the model so the computation graph can be modified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "invs_by_layer, gens = get_random_invariants(model, \n",
    "                                            layers, \n",
    "                                            256, \n",
    "                                            im_tr[0].shape, \n",
    "                                            5, \n",
    "                                            agg_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 13)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(invs_by_layer[0]), len(invs_by_layer[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(conv2d_4[133] > 0.0 &\n",
      " conv2d_4[43] > 0.0 &\n",
      " conv2d_4[1] > 0.0)\n",
      "\t--> Q = 4\n",
      "support=0.0148, precision=1.0\n",
      "(max_pooling2d_4[42] > 0.0 &\n",
      " max_pooling2d_4[43] > 0.0 &\n",
      " max_pooling2d_4[40] > 0.0 &\n",
      " max_pooling2d_4[18] > 0.0)\n",
      "\t--> Q = 0\n",
      "support=0.00193, precision=1.0\n"
     ]
    }
   ],
   "source": [
    "print(invs_by_layer[0][0])\n",
    "print(invs_by_layer[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- training set results, layer 7\n",
      "# invariants per class: {0: 4, 1: 5, 2: 4, 3: 1, 4: 2}\n",
      "support by class: {0: 0.9836956521739131, 1: 0.9148936170212766, 2: 0.9974811083123426, 3: 0.8888888888888888, 4: 0.8585858585858586}\n",
      "precision by class: {0: 0.8916256157635468, 1: 1.0, 2: 0.9974811083123426, 3: 0.972972972972973, 4: 0.8947368421052632}\n",
      "overall prediction accuracy: 0.959\n",
      "---------- test set results, layer 7\n",
      "# invariants per class: {0: 4, 1: 5, 2: 4, 3: 1, 4: 2}\n",
      "support by class: {0: 1.0, 1: 0.9142857142857143, 2: 1.0, 3: 0.9705882352941176, 4: 0.8787878787878788}\n",
      "precision by class: {0: 0.8727272727272727, 1: 1.0, 2: 1.0, 3: 1.0, 4: 0.9666666666666667}\n",
      "overall prediction accuracy: 0.804\n",
      "---------- training set results, layer 8\n",
      "# invariants per class: {0: 3, 1: 3, 2: 4, 3: 2, 4: 1}\n",
      "support by class: {0: 1.0, 1: 0.9893617021276596, 2: 0.9924433249370277, 3: 0.7530864197530864, 4: 1.0}\n",
      "precision by class: {0: 0.9945945945945946, 1: 0.9893617021276596, 2: 1.0, 3: 1.0, 4: 0.8319327731092437}\n",
      "overall prediction accuracy: 0.972\n",
      "---------- test set results, layer 8\n",
      "# invariants per class: {0: 3, 1: 3, 2: 4, 3: 2, 4: 1}\n",
      "support by class: {0: 1.0, 1: 1.0, 2: 0.9925925925925926, 3: 0.7352941176470589, 4: 1.0}\n",
      "precision by class: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 0.7857142857142857}\n",
      "overall prediction accuracy: 0.804\n"
     ]
    }
   ],
   "source": [
    "x_tr, x_te = im_tr, im_te\n",
    "inv_models = [probits_from_invariants(invs) for invs in invs_by_layer]\n",
    "for l in range(len(layers)):\n",
    "    invs = invs_by_layer[l]\n",
    "    inv_model = inv_models[l]\n",
    "    print('-' * 10, 'training set results, layer', layers[l])\n",
    "    n_per, sup, prec = tally_total_stats(\n",
    "        invs, model, x_tr, batch_size=1)\n",
    "    print('# invariants per class:', n_per)\n",
    "    print('support by class:', sup)\n",
    "    print('precision by class:', prec)\n",
    "    print('overall prediction accuracy: {:.3}'.format(\n",
    "        (inv_model(x_tr).argmax(axis=1) == y_tr.argmax(axis=1)).mean()))\n",
    "\n",
    "    print('-' * 10, 'test set results, layer', layers[l])\n",
    "    n_per, sup, prec = tally_total_stats(\n",
    "        invs, model, x_te, batch_size=1)\n",
    "    print('# invariants per class:', n_per)\n",
    "    print('support by class:', sup)\n",
    "    print('precision by class:', prec)\n",
    "    print('overall prediction accuracy: {:.3}'.format(\n",
    "        (inv_model(x_te).argmax(axis=1) == y_te.argmax(axis=1)).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary: random influents invariants at layers 7, 8 achieve 95-97% training accuracy, and 80% test accuracy. The original model achieved 100% training accuracy and 81% test accuracy.\n",
    "\n",
    "Now we'll generate influence invariants with `agg_fn=K.sum`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated class 0\n",
      "generated class 1\n",
      "generated class 2\n",
      "generated class 3\n",
      "generated class 4\n"
     ]
    }
   ],
   "source": [
    "invs_by_layer, gens = get_random_invariants(model, \n",
    "                                            layers, \n",
    "                                            256, \n",
    "                                            im_tr[0].shape, \n",
    "                                            5, \n",
    "                                            agg_fn=K.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- training set results, layer 7\n",
      "# invariants per class: {0: 3, 1: 3, 2: 4, 3: 6, 4: 3}\n",
      "support by class: {0: 0.717391304347826, 1: 0.7021276595744681, 2: 0.7531486146095718, 3: 0.9382716049382716, 4: 0.9393939393939394}\n",
      "precision by class: {0: 0.9850746268656716, 1: 0.9705882352941176, 2: 0.9835526315789473, 3: 0.39790575916230364, 4: 1.0}\n",
      "overall prediction accuracy: 0.836\n",
      "---------- test set results, layer 7\n",
      "# invariants per class: {0: 3, 1: 3, 2: 4, 3: 6, 4: 3}\n",
      "support by class: {0: 0.7291666666666666, 1: 0.7142857142857143, 2: 0.6814814814814815, 3: 1.0, 4: 1.0}\n",
      "precision by class: {0: 1.0, 1: 1.0, 2: 0.989247311827957, 3: 0.4, 4: 1.0}\n",
      "overall prediction accuracy: 0.667\n",
      "---------- training set results, layer 8\n",
      "# invariants per class: {0: 3, 1: 3, 2: 4, 3: 6, 4: 3}\n",
      "support by class: {0: 0.717391304347826, 1: 0.7021276595744681, 2: 0.7531486146095718, 3: 0.9382716049382716, 4: 0.7878787878787878}\n",
      "precision by class: {0: 0.9850746268656716, 1: 0.9705882352941176, 2: 0.9835526315789473, 3: 0.39790575916230364, 4: 1.0}\n",
      "overall prediction accuracy: 0.819\n",
      "---------- test set results, layer 8\n",
      "# invariants per class: {0: 3, 1: 3, 2: 4, 3: 6, 4: 3}\n",
      "support by class: {0: 0.7291666666666666, 1: 0.7142857142857143, 2: 0.6814814814814815, 3: 1.0, 4: 0.7575757575757576}\n",
      "precision by class: {0: 1.0, 1: 1.0, 2: 0.989247311827957, 3: 0.4, 4: 1.0}\n",
      "overall prediction accuracy: 0.649\n"
     ]
    }
   ],
   "source": [
    "x_tr, x_te = im_tr, im_te\n",
    "inv_models = [probits_from_invariants(invs) for invs in invs_by_layer]\n",
    "for l in range(len(layers)):\n",
    "    invs = invs_by_layer[l]\n",
    "    inv_model = inv_models[l]\n",
    "    print('-' * 10, 'training set results, layer', layers[l])\n",
    "    n_per, sup, prec = tally_total_stats(\n",
    "        invs, model, x_tr, batch_size=1)\n",
    "    print('# invariants per class:', n_per)\n",
    "    print('support by class:', sup)\n",
    "    print('precision by class:', prec)\n",
    "    print('overall prediction accuracy: {:.3}'.format(\n",
    "        (inv_model(x_tr).argmax(axis=1) == y_tr.argmax(axis=1)).mean()))\n",
    "\n",
    "    print('-' * 10, 'test set results, layer', layers[l])\n",
    "    n_per, sup, prec = tally_total_stats(\n",
    "        invs, model, x_te, batch_size=1)\n",
    "    print('# invariants per class:', n_per)\n",
    "    print('support by class:', sup)\n",
    "    print('precision by class:', prec)\n",
    "    print('overall prediction accuracy: {:.3}'.format(\n",
    "        (inv_model(x_te).argmax(axis=1) == y_te.argmax(axis=1)).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that aggregating across spatial dimensions does not improve things. This is somewhat surprising especially in the lower recall results, as one might expect spatial dependencies to narrow the scope of an invariant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attribution.methods import InternalInfluence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = Model(model.inputs, model.layers[-2].output)\n",
    "# log_model.layers[-1].activation = keras.activations.softplus\n",
    "# log_model = utils.apply_modifications(log_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_te = im_tr, im_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated class 0\n",
      "generated class 1\n",
      "generated class 2\n",
      "generated class 3\n",
      "generated class 4\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "rand_data = []\n",
    "cls_size = 256\n",
    "rand_x = np.random.uniform(size=(cls_size,) + x_tr.shape[1:])\n",
    "nbiter = 50\n",
    "for l in range(n_classes):\n",
    "    model_ch = KerasModel(model)\n",
    "    sess = K.get_session()\n",
    "    pgd_params_l2 = {'eps': 5.,\n",
    "                     'y_target': to_categorical(np.zeros((1,)) + l, n_classes),\n",
    "                     'eps_iter': 5. / nbiter,\n",
    "                     'nb_iter': nbiter,\n",
    "                     'ord': 2,\n",
    "                     'clip_min': 0.,\n",
    "                     'clip_max': 1.}\n",
    "    pgd_params_linf = {'eps': 0.1,\n",
    "                       'y_target': to_categorical(np.zeros((1,)) + l, n_classes),\n",
    "                       'eps_iter': 0.1 / nbiter,\n",
    "                       'nb_iter': nbiter,\n",
    "                       'ord': np.inf,\n",
    "                       'clip_min': 0.,\n",
    "                       'clip_max': 1.}\n",
    "    pgd = MadryEtAl(model_ch, sess=sess)\n",
    "    cur_data = []\n",
    "    cur_data.append(pgd.generate_np(rand_x, **pgd_params_l2))\n",
    "    cur_data.append(pgd.generate_np(rand_x, **pgd_params_linf))\n",
    "    rand_data.append(np.concatenate(cur_data, axis=0))\n",
    "    print('generated class', l)\n",
    "\n",
    "rand_data = np.concatenate(rand_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "l7inf = [InternalInfluence(log_model, 7, Q=l, multiply_activation=False, agg_fn=None).compile() for l in range(n_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "l6inf = [InternalInfluence(log_model, 6, Q=l, multiply_activation=False, agg_fn=None).compile() for l in range(n_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "l5inf = [InternalInfluence(log_model, 5, Q=l, multiply_activation=False, agg_fn=None).compile() for l in range(n_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr5 = [inf.get_attributions(rand_data, batch_size=1, resolution=100).mean(axis=0) for inf in l5inf]\n",
    "attr6 = [inf.get_attributions(rand_data, batch_size=1, resolution=100).mean(axis=0) for inf in l6inf]\n",
    "attr7 = [inf.get_attributions(rand_data, batch_size=1, resolution=100).mean(axis=0) for inf in l7inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "l7mod = Model(model.input, keras.layers.Flatten()(model.layers[7].output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "x5 = Model(model.input, keras.layers.Flatten()(model.layers[5].output)).predict(x_tr)\n",
    "x6 = Model(model.input, keras.layers.Flatten()(model.layers[6].output)).predict(x_tr)\n",
    "x7 = Model(model.input, keras.layers.Flatten()(model.layers[7].output)).predict(x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "w5 = np.concatenate([np.expand_dims(a, 1) for a in attr5], axis=1)\n",
    "w6 = np.concatenate([np.expand_dims(a, 1) for a in attr6], axis=1)\n",
    "w7 = np.concatenate([np.expand_dims(a, 1) for a in attr7], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4608, 5), (855, 4608))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w5.shape, x5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return e_x / e_x.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.9167502e-12, 8.8507434e-08, 9.9997497e-01, 2.3316581e-05,\n",
       "        1.5533250e-06],\n",
       "       [1.3045338e-08, 1.1155041e-05, 9.8709655e-01, 1.0587788e-02,\n",
       "        2.3045221e-03],\n",
       "       [3.8144074e-02, 2.8108570e-03, 8.3436859e-01, 2.1871267e-04,\n",
       "        1.2445784e-01],\n",
       "       ...,\n",
       "       [4.9721816e-10, 7.2655712e-07, 9.9987125e-01, 1.2318733e-04,\n",
       "        4.7341659e-06],\n",
       "       [9.9999988e-01, 1.0829607e-07, 3.5423171e-09, 4.7654675e-11,\n",
       "        7.5672055e-09],\n",
       "       [1.0000000e+00, 3.6661112e-11, 2.0898318e-11, 4.1094456e-15,\n",
       "        2.4929795e-08]], dtype=float32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(sum([np.dot(x, w) for x, w in zip([x5,x6,x7],[w5,w6,w7])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6865497076023391"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(softmax(sum([np.dot(x, w) for x, w in zip([x5,x6,x7],[w5,w6,w7])])).argmax(axis=1) == log_model.predict(x_tr).argmax(axis=1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.45395380e-13, 1.10029532e-05, 9.99978185e-01, 1.08991335e-05,\n",
       "        2.16627924e-08],\n",
       "       [5.48690196e-07, 1.96373183e-03, 3.56685268e-05, 9.97678220e-01,\n",
       "        3.21844127e-04],\n",
       "       [9.00300394e-04, 9.99049246e-01, 7.68529958e-07, 4.83345466e-05,\n",
       "        1.48542347e-06],\n",
       "       ...,\n",
       "       [5.25505000e-14, 1.50052230e-07, 9.99992132e-01, 7.71383111e-06,\n",
       "        1.97880023e-08],\n",
       "       [1.00000000e+00, 6.47402743e-10, 9.15137420e-25, 7.83871462e-14,\n",
       "        4.75145910e-13],\n",
       "       [9.99997735e-01, 1.88389979e-08, 6.19010323e-19, 8.83451891e-15,\n",
       "        2.30621322e-06]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.0218953e-05, 3.8793101e-03, 9.3963283e-01, 4.6191510e-02,\n",
       "        1.0266158e-02],\n",
       "       [2.6896663e-04, 1.6604017e-02, 4.5552093e-01, 4.6350417e-01,\n",
       "        6.4101979e-02],\n",
       "       [6.2649332e-02, 1.7676464e-01, 4.6528271e-01, 8.2284600e-02,\n",
       "        2.1301873e-01],\n",
       "       ...,\n",
       "       [9.1432215e-05, 4.0450464e-03, 9.4367081e-01, 4.3076344e-02,\n",
       "        9.1162790e-03],\n",
       "       [9.6955103e-01, 2.1163097e-02, 2.2962198e-03, 1.6997319e-03,\n",
       "        5.2899225e-03],\n",
       "       [9.7016978e-01, 6.9086696e-03, 3.6396983e-03, 4.0939538e-04,\n",
       "        1.8872451e-02]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(np.dot(x_l7, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16539453"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.20430478"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01656292, -0.01555725,  0.00356987, -0.02679372, -0.03073645],\n",
       "       [-0.03200556, -0.05438359, -0.01462941, -0.02353186,  0.01667505],\n",
       "       [-0.11667184, -0.00488116,  0.0313616 , -0.08707385, -0.09488193],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.02198535,  0.01360314, -0.00521837, -0.01331311, -0.01470261],\n",
       "       [ 0.01015011, -0.00448576, -0.01429545,  0.00524498, -0.00233526]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "inflinv = InfluenceInvariants(log_model, layer=7, agg_fn=None, multiply_activation=False).compile()\n",
    "invs = inflinv.get_invariants(rand_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(conv2d_4[133] > 0.0 &\n",
      " conv2d_4[43] > 0.0 &\n",
      " conv2d_4[134] > 0.0 &\n",
      " conv2d_4[25] <= -0.5 &\n",
      " conv2d_4[11] <= 0.0)\n",
      "\t--> Q = 0\n",
      "support=0.00193, precision=1.0\n",
      "(conv2d_4[133] > 0.0 &\n",
      " conv2d_4[43] <= 0.0 &\n",
      " conv2d_4[35] > 0.0 &\n",
      " conv2d_4[1] <= 0.0 &\n",
      " conv2d_4[44] <= 0.0)\n",
      "\t--> Q = 0\n",
      "support=0.0193, precision=1.0\n",
      "(conv2d_4[133] > 0.0 &\n",
      " conv2d_4[43] <= 0.0 &\n",
      " conv2d_4[35] <= 0.0 &\n",
      " conv2d_4[175] > -0.5)\n",
      "\t--> Q = 0\n",
      "support=0.973, precision=1.0\n",
      "(conv2d_4[133] <= 0.0 &\n",
      " conv2d_4[139] > 0.0 &\n",
      " conv2d_4[216] <= 0.5 &\n",
      " conv2d_4[224] > -0.5)\n",
      "\t--> Q = 0\n",
      "support=0.00578, precision=1.0\n"
     ]
    }
   ],
   "source": [
    "for inv in [inv for inv in invs if inv.Q == 0]:\n",
    "    print(inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv0 = [inv for inv in invs if inv.Q == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{35, 43, 133, 175}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_invariant_units(inv0[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attribution.invariant_utils import *\n",
    "we = np.array([w[u,0] for u in get_invariant_units(inv0[2])])\n",
    "x_we = x_l7[:,[u for u in get_invariant_units(inv0[2])]]\n",
    "x_we[:,-1] -= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06064251, -0.03093674,  0.00346123,  0.01436928], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "we"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  33,  34,  35,  36,  37,  38,  39,\n",
       "         40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "         53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "        105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "        118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "        131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144,\n",
       "        145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158,\n",
       "        159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
       "        172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
       "        185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
       "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
       "        211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
       "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236,\n",
       "        237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249,\n",
       "        250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262,\n",
       "        263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 274, 275, 276,\n",
       "        277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289,\n",
       "        290, 291, 292, 293, 294, 295, 296, 298, 299, 300, 301, 302, 303,\n",
       "        305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317,\n",
       "        318, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331,\n",
       "        332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344,\n",
       "        345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357,\n",
       "        358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370,\n",
       "        371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383,\n",
       "        384, 385, 386, 387, 388, 389, 391, 392, 394, 395, 396, 397, 398,\n",
       "        399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
       "        412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424,\n",
       "        425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437,\n",
       "        438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
       "        451, 452, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464,\n",
       "        465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477,\n",
       "        478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490,\n",
       "        491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
       "        504, 505, 506, 507, 508, 509, 510, 511, 512, 514, 515, 516, 517,\n",
       "        518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 530, 531,\n",
       "        532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544,\n",
       "        545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 556, 557, 558,\n",
       "        559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n",
       "        573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 584, 585, 586,\n",
       "        587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599,\n",
       "        600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612,\n",
       "        613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 626,\n",
       "        627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 639, 640,\n",
       "        641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653,\n",
       "        654, 655, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668,\n",
       "        669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681,\n",
       "        682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694,\n",
       "        695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707,\n",
       "        708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720,\n",
       "        721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733,\n",
       "        734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746,\n",
       "        747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759,\n",
       "        760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772,\n",
       "        773, 774, 775, 776, 777, 778, 779, 780, 782, 783, 784, 785, 786,\n",
       "        787, 788, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800,\n",
       "        801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813,\n",
       "        814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826,\n",
       "        827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839,\n",
       "        840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852,\n",
       "        853, 854]),)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.dot(x_we, we) >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_we"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[:,0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16476855"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[6,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "features (InputLayer)        (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 128)       3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "logits (Dense)               (None, 5)                 85        \n",
      "=================================================================\n",
      "Total params: 101,589\n",
      "Trainable params: 101,589\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "log_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
